{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Tracker\n",
    "---\n",
    "\n",
    "\n",
    "Tracks products on German \"Kleinanzeigen\" website.\n",
    "\n",
    "This script is for training only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Ask for product-name and keywords\n",
    "\n",
    "**Example Product**: Nikon D 7500\n",
    "\n",
    "**Example Keywords**: Neu Objektiv Kit OVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_input = str(input('Which product are you looking for?'))\n",
    "i = 0\n",
    "product = ''\n",
    "\n",
    "for words in product_input.split(' '):\n",
    "    if i == (len(product_input.split(' '))-1):\n",
    "        product = product + words\n",
    "    else: \n",
    "        product = product + words + '-'\n",
    "    i += 1\n",
    "\n",
    "keys_input = str(input('Which keywords would you like to filter for? (no comma, max. 4)'))\n",
    "i = 0\n",
    "keys = []\n",
    "\n",
    "for words in keys_input.split(' '):\n",
    "    keys += [words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Product list for specific product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking for: Nikon D 7500\n",
      "50 products saved to CSV\n"
     ]
    }
   ],
   "source": [
    "url = f'https://www.kleinanzeigen.de/s-{product}/k0'\n",
    "\n",
    "# count number of subpages\n",
    "\n",
    "p = requests.get(url)\n",
    "website_data = BeautifulSoup(p.text, 'html.parser')\n",
    "number_of_pages = len(website_data.find_all('a', {'class': 'pagination-page'}))\n",
    "\n",
    "# get productlist\n",
    "\n",
    "def get_productlist(url):\n",
    "    \n",
    "    # check each page\n",
    "    for i in range(1,number_of_pages): \n",
    "        if i > 1: \n",
    "            url = f'https://www.kleinanzeigen.de/s-seite:{i}/{product}/k0'\n",
    "        \n",
    "        # get html content\n",
    "        r = requests.get(url)\n",
    "        html_content = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        # get productlist\n",
    "        if i == 1:\n",
    "            productslist = []\n",
    "        results = html_content.find_all('div', {'class': 'aditem-main'})\n",
    "        for item in results:\n",
    "            if item.find('a', {'class': 'ellipsis'}) is not None:\n",
    "                products = {\n",
    "                    'title': item.find('a', {'class': 'ellipsis'}).text.replace(',','.'),\n",
    "                    'price': int(item.find('p', {'class': 'aditem-main--middle--price-shipping--price'}).text.replace(' ','').replace('\\n','').replace('.','').split(\"â‚¬\")[0].replace('VB','0').replace('\"','0')),\n",
    "                    'link': item.find('a', {'class': 'ellipsis'})['href']\n",
    "                }\n",
    "            productslist.append(products)\n",
    "    return productslist\n",
    "\n",
    "def create_dataframe(productslist):\n",
    "    df_products = pd.DataFrame(productslist)\n",
    "    df_products = df_products.sort_values(by=['price'])\n",
    "    df_products.to_csv('products_all.csv', index=False)\n",
    "    print('You are looking for: ' + product_input)\n",
    "    print(len(df_products), 'products saved to CSV')\n",
    "    return df_products\n",
    "\n",
    "df_products = create_dataframe(get_productlist(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Filter for specific content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your keywords are: ['neu', 'Objektiv', 'OVP', 'Kit']\n",
      "14 filtered products saved to CSV\n"
     ]
    }
   ],
   "source": [
    "# optional: reduce list products with keywords\n",
    "\n",
    "print('Your keywords are:', keys)\n",
    "i = 0\n",
    "\n",
    "def find_keywords(df_products):\n",
    "    df_products_key = pd.DataFrame()\n",
    "    for entry in df_products['title']:\n",
    "        if keys[0] in entry or keys[1] in entry or keys[2] in entry or keys[3] in entry:\n",
    "            filtered_entry = df_products[df_products['title'] == entry]\n",
    "            df_products_key = pd.concat([df_products_key, filtered_entry], ignore_index=True)\n",
    "    df_products_key.to_csv('products_key.csv', index=False)\n",
    "    print(len(df_products_key), 'filtered products saved to CSV')\n",
    "\n",
    "find_keywords(df_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get product description of each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column in dataframe\n",
    "df_products_detailed = df_products\n",
    "df_products_detailed[\"description\"] = ' '\n",
    "i = 0\n",
    "\n",
    "# check each page\n",
    "for subpage in df_products['link']:\n",
    "    if type(subpage) == str:\n",
    "        url = 'https://www.kleinanzeigen.de' + subpage\n",
    "        description = ''\n",
    "        q = requests.get(url)\n",
    "        html_content = BeautifulSoup(q.text, 'html.parser')\n",
    "        if html_content.find('p', {'id': 'viewad-description-text'}) is not None:\n",
    "            description = html_content.find('p', {'id': 'viewad-description-text'}).text.replace('\\n',' ').replace('  ','')\n",
    "        df_products_detailed.loc[i,'description'] = description\n",
    "        i += 1\n",
    "\n",
    "df_products_detailed.to_csv('products_detailed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythontest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
